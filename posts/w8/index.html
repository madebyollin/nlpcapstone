<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Week 8 : Advanced Model Attempt II</title>
    <link rel="stylesheet" href="/css/index.css">
    <link rel="icon" href="/images/butterfly.png">
    <link rel="stylesheet"
        href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.7.1/katex.min.css"
        integrity="sha384-wITovz90syo1dJWVh32uuETPVEtGigN07tkttEqPv+uR2SE/mbQcG7ATL28aI9H0"
        crossorigin="anonymous">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.7.1/katex.min.js"
        integrity="sha384-/y1Nn9+QQAipbNQWU65krzJralCnuOasHncUFXGkdwntGeSvQicrYkiUBwsgUqc1"
        crossorigin="anonymous">
    </script>
</head>
<body>
    <div class="post">
        <a class="header" href="/"><span class="butterfly"></span></a>
        <h1>Advanced Model Attempt II</h1>
        <p>We present an advanced model that builds upon our previous advanced model.</p>

        <h2>Pre-processing</h2>
        <p>
            Our corpus is now at 135k tweets! Our tagging scheme remains
            unchanged, but we've moved on to looking into different ways of
            processing our data, starting with different tokenizing engines:
        </p>
        <table>
            <thead>
                <tr>
                    <th>Tokenizer</th>
                    <th>Token count</th>
                    <th>Vocabulary size</th>
                    <th>OOV&nbsp;rate (wrt.&nbsp;GloVe)</th>
                    <th>Validation accuracy</th>
                </tr>
            </thead>
            <tbody>
                <tr>
                    <td><a href="http://www.nltk.org/api/nltk.tokenize.html#nltk.tokenize.casual.TweetTokenizer">NLTK&nbsp;TweetTokenizer</a></td>
                    <td>2207891</td>
                    <td>164370</td>
                    <td>21.55%</td>
                    <td>0.5967</td>
                </tr>
                <tr>
                    <td><a href="https://nlp.stanford.edu/projects/glove/preprocess-twitter.rb">GloVe script</a> *</td>
                    <td>2435201</td>
                    <td>115380</td>
                    <td>29.89%</td>
                    <td>--</td>
                </tr>
            </tbody>
        </table>
        <p>
            <sup>* This script doesn't appear to work correctly, as provided.
            We suspect that this particular script isn't what was actually used
            to tokenize GloVe data (e.g. intended as an example). We'll work on
            fixing it before evaluating its output.</sup>
        </p>

        <h2>Attention Mechanism</h2>
        <p>We have carried out multiple experiments with attention mechanisms in our LSTM classifier.
        In addition, we started using Tensorboard to visualize the learning.</p>

        <p>Recall that for our advanced attempt I, we implemented an initial attention mechanism that
        just scratched the surface.
        It worked by taking the forward LSTM final state, <span class="math-inline">o_\text{fw}</span>,
        and calculating a weighted average of the input word embeddings <span class="math-inline">v_1, \ldots, v_T</span>.
        The weight of each <span class="math-inline">v_t</span> was computed by cosine similarity and then normalized.
        In equations, this basic attention mechanism is:</p>
        
        <div class="katex-math">
            \begin{aligned}
                m &= o_\text{fw} \\[1em]
                e_t &= \frac
                        {v_t \cdot m}
                        {\|v_t\| \|o_\text{fw}\|}
                    \pod\text{cosine similarity} \\[1em]
                \alpha_t &= \frac{\sigma(e_t)}{\sum_{t'=1}^T{\sigma(e_{t'})}}  \pod\text{smoothed} \\[1em]
                h &= \sum_{t'=1}^T{\alpha_t v_t} \\[1em]
                \hat{y} &= softmax(h \mathbf{W_\text{out}} + b_\text{out})
            \end{aligned}
        </div>

        <p>The paper we referenced for this idea uses sigmoid instead of softmax for the weights
        <span class="math-inline">\alpha_t</span> because this formulation apparently "smooths" attention
        across multiple words in the sentence, whereas softmax
        has the effect of "sharpening" attention to focus on just one word.</p>

        <p>For our second advanced model attempt, we explored additional configurations of the attention mechanism:
        As input to the attention mechanism, use combinations of <strong>forward and backward</strong> LSTM states,
        <span class="math-inline">o_\text{fw}</span> and <span class="math-inline">o_\text{bw}</span>:</p>

        <ul>
            <li>
                <strong>Concatenation into a dense layer.</strong> Use the same as above, but redefine
                <div class="katex-math">m = activation \left( [o_\text{fw};\ o_\text{bw}] \mathbf{W_m} + b_m \right)</div>
            </li>
            <li>
                <strong>Element-wise sum.</strong>
                <div class="katex-math">m = o_\text{fw} + o_\text{bw}</div>
            </li>
            <li>
                <strong>Element-wise product.</strong>
                <div class="katex-math">m = o_\text{fw} * o_\text{bw}</div>
            </li>
            <li>
                <strong>Bilinear parameterization instead of cosine similarity.</strong>
                <div class="katex-math">e_t = m \mathbf{W_e} v_t</div>
            </li>
        </ul>

        <h3>Visualizing LSTM attention</h3>

        <div class="attention" data-filepath="fake.json"></div>

        <h3>Attention performance</h3>
        
        <h4>Attention 1</h4>
        <p>
        <span class="katex-math">(o_\text{fw} + o_\text{bw}) \rightarrow \text{cosine similarity}</span>
        </p>
        <img src="attn_sum_cos.png">
        
        <h4>Attention 2</h4>
        <p>
        <span class="katex-math">[o_\text{fw};\ o_\text{bw}] \rightarrow \text{dense} \rightarrow \text{cosine similarity}</span>
        </p>
        <img src="attn_concat_cos.png">
        
        <h4>Attention 3</h4>
        <p>
        <span class="katex-math">(o_\text{fw} + o_\text{bw}) \mathbf{W} v_t \rightarrow \text{cosine similarity}</span>
        </p>
        <img src="attn_bilinear.png">

        <h4>No attention</h4>
        <img src="noattn.png">

        <h3>Conclusion</h3>
        <p>All of our attempted attention mechanisms were wastes of time because they failed
        to improve the classifier. We hypothesize that this is because this type of crude
        attention mechanism effectively forces the model to view the input an averaged bag-of-words.
        It seems to run counter to the spirit of the LSTM, which is to remember the order of the words.
        As far as the classifier is concerned,
        we're exactly where we were two weeks ago.
        The only improvement we've made in the classifier is the addition of more training tweets.
        </p>

        <h2>Other Stuff</h2>
    </div>
    <script async src="//platform.twitter.com/widgets.js" charset="utf-8"></script>
    <script src="/js/applykatex.js"></script>
    <script src="/js/attention.js"></script>
</body>
</html>
