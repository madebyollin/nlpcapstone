<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Week 6 : Advanced Model Attempt I</title>
    <link rel="stylesheet" href="/css/index.css">
    <link rel="icon" href="/images/butterfly.png">
    <link rel="stylesheet"
        href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.7.1/katex.min.css"
        integrity="sha384-wITovz90syo1dJWVh32uuETPVEtGigN07tkttEqPv+uR2SE/mbQcG7ATL28aI9H0"
        crossorigin="anonymous">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.7.1/katex.min.js"
        integrity="sha384-/y1Nn9+QQAipbNQWU65krzJralCnuOasHncUFXGkdwntGeSvQicrYkiUBwsgUqc1"
        crossorigin="anonymous">
    </script>
</head>
<body>
    <div class="post">
        <a class="header" href="/"><span class="butterfly"></span></a>
        <h1>Advanced Model Attempt I</h1>
        <p>We present an advanced model that builds upon our <a href="/posts/w4/">strawman</a> <a href="/posts/w5/">models</a>.</p>

        <h2>Data Collection</h2>
        <p>
            Based on our error analysis from the strawman attempts and the
            feedback from our in-class presentation, we have refined our data
            collection process slightly:
            <ul>
                <li>
                    <strong>Reduced emotion palette</strong>: our emotion
                    tagger was not classifying "neutral" or "surprised" tweets
                    accurately enough to merit continuing to collect tweets in
                    either category. This is not unreasonable; it seems
                    unlikely that Twitter users would bother sending out a
                    status update if they were feeling completely neutral at
                    the moment!
                </li>
                <li>
                    <strong>Expanded corpus</strong>: in addition to reducing
                    our emotion palette, we also adjusted our emoji-emotion
                    mappings slightly, which has had a net effect of
                    streamlining our data collection process. We now have over
                    nine thousand tweets for each emotion!
                </li>
            </ul>
        </p>

        <h2>Classifier</h2>

        <p>We have continued to build upon our strawman classifiers by:</p>
        <ul>
            <li>Obtaining an <strong>emotional lexicon</strong> data set and applying this in a bag-of-words model
            and in an LSTM model</li>
            <li>Implementing a <strong>bidirectional word-level LSTM</strong></li>
        </ul>

        <h3>Emotional Lexicon</h3>

        <p>We requested and obtained a copy of a <a href="http://saifmohammad.com/WebPages/NRC-Emotion-Lexicon.htm">word-emotion association lexicon</a>, also known as EmoLex, thanks to
        research by Saif Mohammad and Pierre Charron <a class="tag" href="#f1">[1]</a>. This lexicon contains 14,182 words.
        Each word is scored either 0 or 1 for each of eight emotions (anger, anticipation, disgust, fear, joy, sadness, surprise, trust) and also 0 or 1 for positive and negative sentiments. 
        We applied these associations in a bag-of-words model by summing the associations for every word in the sentence into a 10-dimensional
        vector and feeding this into a linear model.</p>

        <p>We also tried feeding the 10-dimensional associations as a sequence into an LSTM.</p>

        <p>The performance of both models was unsatisfactory. This may be because the vocabulary is small, and
        so our tweet samples suffer from a large number of OOV words. About 10% of our collected tweets are completely OOV with respect
        to EmoLex. In fact, over the entire training set, only 16.3% of the words observed <em>are</em> in EmoLex.</p>

        <h3>Word-level LSTM</h3>

        <p>To overcome the poor performance of the character LSTM and EmoLex attempts, we moved on to
        a word-level LSTM using GloVe vectors.</p>
        
        <p>As input, the model receives a sentence represented as a sequence of 200-dimensional word embeddings.
        In training, we initialize the word embedding matrix with GloVe's Twitter embeddings <a class="tag" href="#f2">[2]</a>
        and allow the gradients to backpropagate to the embedding matrix for the first few epochs. The idea is to allow
        the LSTM to fine-tune the embeddings because general-purpose embeddings can have some undesirable properties; for example, it
        is often the case that antonyms are nearest neighbors of each other, which is detrimental to sentiment and emotion classification.
        After letting the model enhance the embeddings, we freeze the embedding matrix
        and continue training the rest of the model's parameters. We also apply 50% dropout to the LSTM cell inputs
        and outputs.
        </p>

        <h3>Classifier Metrics</h3>

        <table>
            <thead>
                <tr>
                    <td>Model name</td>
                    <td>Train accuracy</td>
                    <td>Validation accuracy</td>
                </tr>
            </thead>
            <tbody>
                <tr>
                    <td>Most frequent class</td>
                    <td>33.4%</td>
                    <td>33.0%</td>
                </tr>
                <tr>
                    <td>Bag-of-words linear model</td>
                    <td>63.2%</td>
                    <td>52.1%</td>
                </tr>
                <tr>
                    <td>EmoLex bag-of-words linear model</td>
                    <td>40.9%</td>
                    <td>40.5%</td>
                </tr>
                <tr>
                    <td>EmoLex LSTM</td>
                    <td>42.6%</td>
                    <td>43.2%</td>
                </tr>
                <tr>
                    <td>Word-level bidirectional LSTM</td>
                    <td></td>
                    <td>58.8%</td>
                </tr>
            </tbody>
        </table>

        <h2>Text to Speech</h2>
        <p>In preparation for a style-transfer based model for emotional text to speech, we've begun experimenting with conditional GANs for phase reconstruction.</p>
        <p>Phase reconstruction is the task of generating plausible phase information given an amplitude signal; the current version of the model uses a successive approximation algorithm to do this, but results sound imperfect.</p>
        <p>Although phase reconstruction is a simpler task than our ultimate goal of emotion transfer, it is simple yet underspecified and therefore presents a good test case for adversarial models.</p>
        <h3>Samples</h3>
        <p>Some samples from various iterations of the adversarial phase reconstruction are as follows (following <code>tanh</code> + normalization):</p>
        <img src="gan.png"/>
        <p>In contrast, real phase data (again, normalized, and for different training tiles) looks like this:</p>
        <img src="real.png"/>
        <p>There is a clear difference in distributions, even among the closest iterations of the generator.  Simply increasing the capacity of the generator and discriminator has thus far led to collapse of the model, however (rather than more realistic results).</p>
        <h3>Conclusion</h3>
        <p>In short, training is not yet sufficient to produce compelling results for phase reconstruction, and some further modifications to model architecture will be required.  If successful, an adversarial phase reconstruction model will not only improve the quality of emotional text to speech under the current baseline algorithm, but also give useful insights and techniques for building our target text-to-speech processing model.</p>

        <p class="footnote" id="f1">
            <span class="tag">1</span> Saif Mohammad, Pierre Charron. NRC Word-Emotion Association Lexicon.
        </p>
        <p class="footnote" id="f2">
            <span class="tag">2</span> Jeffrey Pennington, Richard Socher, and Christopher D. Manning. 2014. GloVe: Global Vectors for Word Representation.
        </p>
    </div>
    <script async src="//platform.twitter.com/widgets.js" charset="utf-8"></script>
    <script src="/js/applykatex.js"></script>
</body>
</html>
